{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302d37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc0b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_dir_exists(dir_to_check):\n",
    "    if not os.path.exists(dir_to_check):\n",
    "        os.makedirs(dir_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r External_data/\n",
    "# !rm -r External_data_tidied/\n",
    "# !rm -r External_data_tidied_combined_used_to_train_DREAM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62d0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the orginal external datasets in a folder named \"External_data\"\n",
    "!mkdir External_data\n",
    "\n",
    "# We will store the extracted information from external datasets that we use \n",
    "# to build our Scene Elaboration (SE) dataset in a folder named \"External_data_tidied\"\n",
    "!mkdir External_data_tidied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24778c",
   "metadata": {},
   "source": [
    "## External dataset: Social Chemistry\n",
    "To get rule of thumbs (ROT component of SE) in External_data_tidied/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e0b63",
   "metadata": {},
   "source": [
    "Download the source dataset :\n",
    "1. Visit the website for the Social Chemistry project https://maxwellforbes.com/social-chemistry/ \n",
    "2. Scroll down to the \"QUICK INFO\" part, find the third column \"DATA\", \"Social-Chem-101 Dataset 4.5M+ annotations 28 MB .zip\" to \"DOWNLOAD\" the source data\n",
    "3. Unzip the downloaded file and place it in \"External_data\" folder we created\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e439b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data_sc_as_rot():\n",
    "    dataset = \"social_chemistry\"\n",
    "    out_dir = \"External_data_tidied\"\n",
    "    scene_part = \"rot\" # what might other people say\n",
    "    out_paths = []\n",
    "    for train_dev_test in [\"training\", \"dev\", \"test\"]:\n",
    "        out_path = \"/\".join([out_dir, scene_part , train_dev_test]) + \".json\"\n",
    "        out_paths.append(out_path)\n",
    "        make_sure_dir_exists(\"/\".join([out_dir, scene_part]))\n",
    "    \n",
    "    infile = \"External_data/social-chem-101/social-chem-101.v1.0.tsv\"\n",
    "\n",
    "    judgment_types = []\n",
    "    with open(infile, \"r\") as datafile, \\\n",
    "        open(out_paths[0], \"w\") as json_train, open(out_paths[1], \"w\") as json_dev, \\\n",
    "        open(out_paths[2], \"w\") as json_test :\n",
    "\n",
    "        data = csv.reader(datafile, delimiter = \"\\t\")\n",
    "        data_split_idx = -1\n",
    "        situation_idx = -1\n",
    "        rot_idx = -1\n",
    "        short_judgement_idx = -1\n",
    "        \n",
    "        id_cnt = 1\n",
    "        train_cnt = 0\n",
    "        dev_cnt = 0\n",
    "        test_cnt = 0\n",
    "        for i, annotation in enumerate(data):\n",
    "            if i == 0:\n",
    "                data_split_idx = annotation.index(\"split\")\n",
    "                situation_idx = annotation.index(\"situation\")\n",
    "                rot_idx = annotation.index(\"rot\")\n",
    "                short_judgement_idx = annotation.index(\"rot-judgment\")\n",
    "\n",
    "            else:  \n",
    "                target_out = \"\"\n",
    "                data_split = annotation[data_split_idx]\n",
    "                situation = annotation[situation_idx]\n",
    "                rot = annotation[rot_idx]\n",
    "                short_judgement = annotation[short_judgement_idx].lower()\n",
    "                \n",
    "                if short_judgement not in judgment_types:\n",
    "                    judgment_types.append(short_judgement)\n",
    "                train_dev_test = data_split\n",
    "                if data_split == \"train\":\n",
    "                    json_file = json_train\n",
    "                    train_dev_test = \"training\"\n",
    "                    train_cnt += 1\n",
    "                elif data_split == \"dev\":\n",
    "                    json_file = json_dev\n",
    "                    dev_cnt +=1\n",
    "                else:\n",
    "                    json_file = json_test\n",
    "                    test_cnt +=1\n",
    "                \n",
    "                if not situation.endswith(\".\"):\n",
    "                    situation += \".\"\n",
    "                    \n",
    "                if rot != \"\" and not rot.endswith(\".\"):\n",
    "                        rot += \".\"\n",
    "                json_file.write(json.dumps({\"dataset\": dataset , \"id\":  dataset  + \"_\" + train_dev_test + \"_\" + str(id_cnt), \\\n",
    "                \"question\": \"[SITUATION] \" + situation + \" [QUERY] \" + scene_part, \\\n",
    "                \"answer\": rot}))\n",
    "                json_file.write(\"\\n\")\n",
    "                json_file.flush()\n",
    "                id_cnt += 1\n",
    "\n",
    "        print(\"=\" * 10, scene_part, \"=\" * 10)\n",
    "        print(\"Total :\", id_cnt - 1)\n",
    "        print(\"train :\", train_cnt)\n",
    "        print(\"dev :\", dev_cnt)\n",
    "        print(\"test :\", test_cnt)\n",
    "        #print(\"judgement_types:\", judgment_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13eace51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== rot ==========\n",
      "Total : 355922\n",
      "train : 233501\n",
      "dev : 29234\n",
      "test : 93187\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You'd expect the following output from running the next line:\n",
    "========== rot ==========\n",
    "Total : 355922\n",
    "train : 233501\n",
    "dev : 29234\n",
    "test : 93187\n",
    "'''\n",
    "\n",
    "organize_data_sc_as_rot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c87ed0",
   "metadata": {},
   "source": [
    "## External dataset: Story Commonsense\n",
    "To get Motivation, Emotion in External_data_tidied/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56c55a",
   "metadata": {},
   "source": [
    "Download the source dataset :\n",
    "1. Visit the website for the Story Commonsense project https://uwnlp.github.io/storycommonsense/\n",
    "2. At the top of the page, where the \"Quick links\" are, click \"[download the data]\"\n",
    "3. Unzip the downloaded file and place it in \"External_data\" folder we created\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4457cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data_story_commonsense(train_dev_test, scene_part):\n",
    "    '''\n",
    "    Input strings:\n",
    "    train_dev_test : \"training\"/ \"dev\"/ \"test\"\n",
    "    scene_part : \"emotion\", \"motivation\"\n",
    "    '''\n",
    "    dataset = \"story_commonsense\"\n",
    "    out_dir = \"External_data_tidied\"\n",
    "    out_path = \"/\".join([out_dir, scene_part,train_dev_test]) + \".json\"\n",
    "    make_sure_dir_exists(\"/\".join([out_dir, scene_part]))\n",
    "    \n",
    "    if train_dev_test == \"training\":\n",
    "        infile = \"External_data/storycommonsense_data/csv_version/\" + train_dev_test + \"/allcharlinepairs.csv\"\n",
    "    else:\n",
    "        if scene_part == \"emotion\":\n",
    "            infile = \"External_data/storycommonsense_data/csv_version/\" + train_dev_test + \"/\" + scene_part + \"/allcharlinepairs.csv\"\n",
    "        elif scene_part == \"motivation\":\n",
    "            infile = \"External_data/storycommonsense_data/csv_version/\" + train_dev_test + \"/motiv/allcharlinepairs.csv\"\n",
    "\n",
    "\n",
    "    with open(infile, \"r\") as datafile, \\\n",
    "        open(out_path, \"w\") as json_file:\n",
    "\n",
    "        data = csv.reader(datafile)\n",
    "        sentence_idx = -1\n",
    "        character_idx = -1\n",
    "        target_idx = -1\n",
    "        id_cnt = 1 \n",
    "        for i, annotation in enumerate(data):\n",
    "            if i == 0:\n",
    "                sentence_idx = annotation.index(\"sentence\")\n",
    "                character_idx = annotation.index(\"char\")\n",
    "                target_idx = annotation.index(scene_part)\n",
    "\n",
    "            else:  \n",
    "                situation = annotation[sentence_idx].strip()\n",
    "                \n",
    "                if annotation[target_idx] == \"[\\\"none\\\"]\":\n",
    "                    target_out = \"\"\n",
    "                else:\n",
    "                    processed_annotation = json.loads(annotation[target_idx])\n",
    "                    processed_annotation = \", \".join([x.lower() for x in processed_annotation])\n",
    "                    target_out = get_possessive_form(annotation[character_idx]).capitalize() + \" \" + scene_part + \" is \" + processed_annotation\n",
    "                    if target_out != \"\" and not target_out.endswith(\".\"):\n",
    "                        target_out += \".\"\n",
    "\n",
    "                #print(situation, target_out) \n",
    "                if not situation.endswith(\".\"):\n",
    "                    situation += \".\"\n",
    "\n",
    "                json_file.write(json.dumps({\"dataset\": dataset , \"id\":  dataset  + \"_\" + train_dev_test + \"_\" + str(id_cnt), \\\n",
    "                                \"question\": \"[SITUATION] \" + situation + \" [QUERY] \" + scene_part, \\\n",
    "                                \"answer\": target_out}))\n",
    "                json_file.write(\"\\n\")\n",
    "                json_file.flush()\n",
    "                id_cnt += 1\n",
    "\n",
    "        print(\"=\" * 10, train_dev_test, \"|\", scene_part, \"=\" * 10)\n",
    "        print(\"Total :\", id_cnt - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31e446c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== training | emotion ==========\n",
      "Total : 174691\n",
      "========== training | motivation ==========\n",
      "Total : 174691\n",
      "========== dev | emotion ==========\n",
      "Total : 53234\n",
      "========== dev | motivation ==========\n",
      "Total : 47547\n",
      "========== test | emotion ==========\n",
      "Total : 51891\n",
      "========== test | motivation ==========\n",
      "Total : 39359\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You'd expect the following output from running the next few lines:\n",
    "========== training | emotion ==========\n",
    "Total : 174691\n",
    "========== training | motivation ==========\n",
    "Total : 174691\n",
    "========== dev | emotion ==========\n",
    "Total : 53234\n",
    "========== dev | motivation ==========\n",
    "Total : 47547\n",
    "========== test | emotion ==========\n",
    "Total : 51891\n",
    "========== test | motivation ==========\n",
    "Total : 39359\n",
    "'''\n",
    "for train_dev_test in [\"training\", \"dev\", \"test\"]:\n",
    "    for scene_part in [\"emotion\", \"motivation\"]:\n",
    "        organize_data_story_commonsense(train_dev_test, scene_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376f296",
   "metadata": {},
   "source": [
    "## External dataset: Moral Stories\n",
    "To get moral, immoral_consequences in External_data_tidied/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64ea4a",
   "metadata": {},
   "source": [
    "Download the source dataset :\n",
    "1. The Moral Stories dataset is available at https://tinyurl.com/moral-stories-data\n",
    "2. \"Download\" the compressed file from the link above \n",
    "3. Expand the downloaded file and place it in \"External_data\" folder we created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32122230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_data_moral_stories(scene_part, train_dev_test):\n",
    "    '''\n",
    "    Input strings:\n",
    "    train_dev_test : \"training\"/ \"dev\"/ \"test\"\n",
    "    scene_part : \"consequence\"\n",
    "    '''\n",
    "    dataset = \"moral_stories\"\n",
    "    \n",
    "    out_dir = \"External_data_tidied\"\n",
    "    out_path = \"/\".join([out_dir, scene_part , train_dev_test]) + \".json\"\n",
    "    make_sure_dir_exists(\"/\".join([out_dir, scene_part]))\n",
    "    \n",
    "    if train_dev_test == \"training\":\n",
    "        infile = \"External_data/\" + dataset + \"_datasets/generation/consequence|action+context/norm_distance/train.jsonl\"\n",
    "    else:\n",
    "        infile = \"External_data/\" + dataset + \"_datasets/generation/consequence|action+context/norm_distance/\" + train_dev_test + \".jsonl\"\n",
    "\n",
    "    with open(infile, \"r\") as datafile, open(out_path, \"w\") as json_file :\n",
    "\n",
    "        data = datafile.readlines()\n",
    "        \n",
    "\n",
    "        id_cnt = 1\n",
    "        for i, data_line in enumerate(data):\n",
    "            annotation = json.loads(data_line)\n",
    "            situation = annotation[\"situation\"]\n",
    "            tag = \"\"\n",
    "            \n",
    "            if \"moral_action\" in annotation:\n",
    "                action = annotation[\"moral_action\"]\n",
    "                consequence = annotation[\"moral_consequence\"]\n",
    "                tag = \"[moral_consequence]\"\n",
    "\n",
    "            elif \"immoral_action\" in annotation:\n",
    "                action = annotation[\"immoral_action\"]\n",
    "                consequence = annotation[\"immoral_consequence\"]\n",
    "                tag = \"[immoral_consequence]\"\n",
    "\n",
    "            json_file.write(json.dumps({\"dataset\": dataset , \"id\":  dataset  + \"_\" + train_dev_test + \"_\" + str(id_cnt), \\\n",
    "            \"question\": \"[SITUATION] \" + situation + \" \" + action + \" [QUERY] \" + scene_part, \\\n",
    "            \"answer\": tag + \" \" + consequence}))\n",
    "            \n",
    "            json_file.write(\"\\n\")\n",
    "            json_file.flush()\n",
    "            id_cnt += 1\n",
    "            \n",
    "\n",
    "        print(\"=\" * 10, train_dev_test, \"|\", scene_part, \"=\" * 10)\n",
    "        print(\"Total :\", id_cnt - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f16be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== training | consequence ==========\n",
      "Total : 20000\n",
      "========== dev | consequence ==========\n",
      "Total : 2000\n",
      "========== test | consequence ==========\n",
      "Total : 2000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You'd expect the following output from running the next few lines:\n",
    "========== training | consequence ==========\n",
    "Total : 20000\n",
    "========== dev | consequence ==========\n",
    "Total : 2000\n",
    "========== test | consequence ==========\n",
    "Total : 2000\n",
    "'''\n",
    "for train_dev_test in [\"training\", \"dev\", \"test\"]:\n",
    "    for scene_part in [\"consequence\"]:\n",
    "        organize_data_moral_stories(scene_part, train_dev_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaefe72",
   "metadata": {},
   "source": [
    "## Combine data\n",
    "\n",
    "Downsample to make the training size from each source data is more blanaced.\n",
    "\n",
    "Combine the sampled scene components into one folder (with training/dev/test files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e860e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.json\n",
      "========== Copying data from rot subfolder... ==========\n",
      "Original total size 233501\n",
      "External_data_tidied/rot/training.json copied! Copied 23350 lines.\n",
      "========== Copying data from consequence subfolder... ==========\n",
      "Original total size 20000\n",
      "External_data_tidied/consequence/training.json copied! Copied 20000 lines.\n",
      "========== Copying data from emotion subfolder... ==========\n",
      "Original total size 174691\n",
      "non-empty sampled 15722\n",
      "empty sampled 1746\n",
      "total sampled 17468\n",
      "External_data_tidied/emotion/training.json copied! Copied 17468 lines.\n",
      "========== Copying data from motivation subfolder... ==========\n",
      "Original total size 174691\n",
      "non-empty sampled 15722\n",
      "empty sampled 1746\n",
      "total sampled 17468\n",
      "External_data_tidied/motivation/training.json copied! Copied 17468 lines.\n",
      "dev.json\n",
      "========== Copying data from rot subfolder... ==========\n",
      "Original total size 29234\n",
      "External_data_tidied/rot/dev.json copied! Copied 2923 lines.\n",
      "========== Copying data from consequence subfolder... ==========\n",
      "Original total size 2000\n",
      "External_data_tidied/consequence/dev.json copied! Copied 2000 lines.\n",
      "========== Copying data from emotion subfolder... ==========\n",
      "Original total size 53234\n",
      "non-empty sampled 4791\n",
      "empty sampled 532\n",
      "total sampled 5323\n",
      "External_data_tidied/emotion/dev.json copied! Copied 5323 lines.\n",
      "========== Copying data from motivation subfolder... ==========\n",
      "Original total size 47547\n",
      "non-empty sampled 4279\n",
      "empty sampled 475\n",
      "total sampled 4754\n",
      "External_data_tidied/motivation/dev.json copied! Copied 4754 lines.\n",
      "test.json\n",
      "========== Copying data from rot subfolder... ==========\n",
      "Original total size 93187\n",
      "External_data_tidied/rot/test.json copied! Copied 9318 lines.\n",
      "========== Copying data from consequence subfolder... ==========\n",
      "Original total size 2000\n",
      "External_data_tidied/consequence/test.json copied! Copied 2000 lines.\n",
      "========== Copying data from emotion subfolder... ==========\n",
      "Original total size 51891\n",
      "non-empty sampled 4670\n",
      "empty sampled 518\n",
      "total sampled 5188\n",
      "External_data_tidied/emotion/test.json copied! Copied 5188 lines.\n",
      "========== Copying data from motivation subfolder... ==========\n",
      "Original total size 39359\n",
      "non-empty sampled 3542\n",
      "empty sampled 393\n",
      "total sampled 3935\n",
      "External_data_tidied/motivation/test.json copied! Copied 3935 lines.\n",
      "THIS DATASET HAS A TOTAL OF 113727 LINES!\n"
     ]
    }
   ],
   "source": [
    "outdir = \"External_data_tidied_combined_used_to_train_DREAM/\"\n",
    "make_sure_dir_exists(outdir)\n",
    "\n",
    "file_names = [\"training.json\", \"dev.json\", \"test.json\"]\n",
    "global_final_new_data = 0 \n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    with open(outdir + file_name, \"w\") as outfile:\n",
    "        for folder in os.listdir(\"External_data_tidied/\"):\n",
    "\n",
    "            if os.path.isfile(\"External_data_tidied/\" + folder):\n",
    "                continue # we want to copy from data folders, skip README file etc\n",
    "            print(\"=\" * 10, \"Copying data from\", folder, \"subfolder...\", \"=\" * 10)\n",
    "            with open(\"External_data_tidied/\" + folder + \"/\" + file_name , 'r') as infile:\n",
    "                \n",
    "                # read all lines from file\n",
    "                infile_lines = infile.readlines()\n",
    "                total_num_of_lines = len(infile_lines)\n",
    "                print(\"Original total size\", total_num_of_lines)\n",
    "                \n",
    "                if folder in [\"motivation\", \"emotion\"]:\n",
    "                    ###\n",
    "                    # For motivation (M) and emotion (E) components, sample 10% ~175k -> ~17.5K\n",
    "                    # too much blanks, sample to control that 90% is not blank\n",
    "                    ###\n",
    "                    non_empty_line_ids = [i for i, line in enumerate(infile_lines) if json.loads(line)[\"answer\"] != \"\"]\n",
    "                    empty_line_ids = [i for i, line in enumerate(infile_lines) if json.loads(line)[\"answer\"] == \"\"]\n",
    "                    assert len(set(non_empty_line_ids) & set(empty_line_ids)) == 0\n",
    "                    assert len(non_empty_line_ids) + len(empty_line_ids) == total_num_of_lines\n",
    "                    \n",
    "                    random.seed(12345)\n",
    "                    sampled_line_nums_non_empty = random.sample(non_empty_line_ids, int((total_num_of_lines * 0.9) // 10))\n",
    "                    print(\"non-empty sampled\", len(sampled_line_nums_non_empty))\n",
    "                    random.seed(12345)\n",
    "                    sampled_line_nums_empty = random.sample(empty_line_ids, int((total_num_of_lines * 0.1) // 10))\n",
    "                    print(\"empty sampled\", len(sampled_line_nums_empty))\n",
    "                    \n",
    "                    sampled_line_nums = sampled_line_nums_non_empty + sampled_line_nums_empty\n",
    "                    print(\"total sampled\", len(sampled_line_nums))\n",
    "                    \n",
    "                    if len(sampled_line_nums) - (total_num_of_lines // 10) > 10:\n",
    "                        print(len(sampled_line_nums), total_num_of_lines)\n",
    "                else:\n",
    "                    ###\n",
    "                    # For rule of thumb a.k.a social norm (ROT) component, sample 10% ~233k -> ~23K\n",
    "                    ###\n",
    "                    random.seed(12345)\n",
    "                    sampled_line_nums = random.sample(list(range(total_num_of_lines)), total_num_of_lines // 10)\n",
    "                \n",
    "                written_to_file_cnt = 0\n",
    "                for i, line in enumerate(infile_lines):\n",
    "                    if folder.endswith(\"consequence\"):\n",
    "                        ###\n",
    "                        # For Consequence (Con) component, this dataset is smaller, so no need to sample\n",
    "                        ###\n",
    "                        written_to_file_cnt += 1\n",
    "                        outfile.write(line)\n",
    "                    else:\n",
    "                        if i in sampled_line_nums:\n",
    "                            written_to_file_cnt += 1\n",
    "                            outfile.write(line)\n",
    "                            \n",
    "                if folder.endswith(\"consequence\"):      \n",
    "                    # this dataset is small, copy everything\n",
    "                    assert written_to_file_cnt == total_num_of_lines\n",
    "                else:\n",
    "                    assert written_to_file_cnt == len(sampled_line_nums)\n",
    "                    \n",
    "            global_final_new_data += written_to_file_cnt\n",
    "            print(\"External_data_tidied/\" + folder + \"/\" + file_name, \"copied!\", \"Copied\", written_to_file_cnt, \"lines.\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "print(\"THIS DATASET HAS A TOTAL OF\", global_final_new_data, \"LINES!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You'd expect the following output from running the above lines:\n",
    "training.json\n",
    "========== Copying data from rot subfolder... ==========\n",
    "Original total size 233501\n",
    "External_data_tidied/rot/training.json copied! Copied 23350 lines.\n",
    "========== Copying data from consequence subfolder... ==========\n",
    "Original total size 20000\n",
    "External_data_tidied/consequence/training.json copied! Copied 20000 lines.\n",
    "========== Copying data from emotion subfolder... ==========\n",
    "Original total size 174691\n",
    "non-empty sampled 15722\n",
    "empty sampled 1746\n",
    "total sampled 17468\n",
    "External_data_tidied/emotion/training.json copied! Copied 17468 lines.\n",
    "========== Copying data from motivation subfolder... ==========\n",
    "Original total size 174691\n",
    "non-empty sampled 15722\n",
    "empty sampled 1746\n",
    "total sampled 17468\n",
    "External_data_tidied/motivation/training.json copied! Copied 17468 lines.\n",
    "dev.json\n",
    "========== Copying data from rot subfolder... ==========\n",
    "Original total size 29234\n",
    "External_data_tidied/rot/dev.json copied! Copied 2923 lines.\n",
    "========== Copying data from consequence subfolder... ==========\n",
    "Original total size 2000\n",
    "External_data_tidied/consequence/dev.json copied! Copied 2000 lines.\n",
    "========== Copying data from emotion subfolder... ==========\n",
    "Original total size 53234\n",
    "non-empty sampled 4791\n",
    "empty sampled 532\n",
    "total sampled 5323\n",
    "External_data_tidied/emotion/dev.json copied! Copied 5323 lines.\n",
    "========== Copying data from motivation subfolder... ==========\n",
    "Original total size 47547\n",
    "non-empty sampled 4279\n",
    "empty sampled 475\n",
    "total sampled 4754\n",
    "External_data_tidied/motivation/dev.json copied! Copied 4754 lines.\n",
    "test.json\n",
    "========== Copying data from rot subfolder... ==========\n",
    "Original total size 93187\n",
    "External_data_tidied/rot/test.json copied! Copied 9318 lines.\n",
    "========== Copying data from consequence subfolder... ==========\n",
    "Original total size 2000\n",
    "External_data_tidied/consequence/test.json copied! Copied 2000 lines.\n",
    "========== Copying data from emotion subfolder... ==========\n",
    "Original total size 51891\n",
    "non-empty sampled 4670\n",
    "empty sampled 518\n",
    "total sampled 5188\n",
    "External_data_tidied/emotion/test.json copied! Copied 5188 lines.\n",
    "========== Copying data from motivation subfolder... ==========\n",
    "Original total size 39359\n",
    "non-empty sampled 3542\n",
    "empty sampled 393\n",
    "total sampled 3935\n",
    "External_data_tidied/motivation/test.json copied! Copied 3935 lines.\n",
    "THIS DATASET HAS A TOTAL OF 113727 LINES!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecd559",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "### We now use this external data to create our scene generation model DREAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac7708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
